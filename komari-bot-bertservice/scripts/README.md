# å®ç”¨å·¥å…·è„šæœ¬

æœ¬ç›®å½•åŒ…å«ç”¨äºæ¨¡å‹ç®¡ç†ã€æ€§èƒ½æµ‹è¯•ã€æ•°æ®å¤„ç†å’Œå¥åº·æ£€æŸ¥çš„å®ç”¨è„šæœ¬ã€‚

## ä¾èµ–å®‰è£…

éƒ¨åˆ†è„šæœ¬éœ€è¦é¢å¤–çš„ä¾èµ–ï¼š

**Poetryï¼ˆå¼€å‘ç¯å¢ƒï¼‰ï¼š**

```bash
poetry install --with scripts
```

**pipï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰ï¼š**

```bash
pip install huggingface-hub google-genai tqdm
```

## å¯ç”¨è„šæœ¬

### process_chat.py

å¤„ç† QQ ç¾¤èŠå¤©è®°å½•å¯¼å‡ºçš„ JSON æ–‡ä»¶ï¼Œç”Ÿæˆå¯ç”¨äºæ¨¡å‹è®­ç»ƒæˆ–æ¨ç†çš„æ•°æ®ã€‚

**åŠŸèƒ½ï¼š**

- åªä¿ç•™çº¯æ–‡æœ¬æ¶ˆæ¯ï¼ˆtype ä¸º textï¼‰
- è¿‡æ»¤æ— æ•ˆæ–‡æœ¬ï¼ˆæŒ‡ä»¤ã€@æåŠã€CQ ç ç­‰ï¼‰
- åˆå¹¶å•ä¸ªç”¨æˆ· 15 ç§’å†…å‘é€çš„è¿ç»­æ¶ˆæ¯
- å¯¼å‡ºä¸ºç®€åŒ–çš„ JSON æ ¼å¼

**ç”¨æ³•ï¼š**

```bash
python scripts/process_chat.py input.json -o output.json
```

**å‚æ•°ï¼š**

| å‚æ•°              | è¯´æ˜                       | é»˜è®¤å€¼                      |
| ----------------- | -------------------------- | --------------------------- |
| `input_file`      | è¾“å…¥ JSON æ–‡ä»¶è·¯å¾„ï¼ˆå¿…éœ€ï¼‰ | -                           |
| `-o, --output`    | è¾“å‡º JSON æ–‡ä»¶è·¯å¾„         | `è¾“å…¥æ–‡ä»¶å_processed.json` |
| `-t, --threshold` | åˆå¹¶é˜ˆå€¼ï¼ˆç§’ï¼‰             | `15`                        |

**ç¤ºä¾‹ï¼š**

```bash
# ä½¿ç”¨é»˜è®¤è¾“å‡ºæ–‡ä»¶å
python scripts/process_chat.py chat.json

# æŒ‡å®šè¾“å‡ºæ–‡ä»¶
python scripts/process_chat.py chat.json -o processed_chat.json

# è‡ªå®šä¹‰åˆå¹¶é˜ˆå€¼ï¼ˆ30 ç§’ï¼‰
python scripts/process_chat.py chat.json -t 30
```

**è¾“å…¥æ ¼å¼ï¼š**

```json
{
  "messages": [
    {
      "type": "type_1",
      "sender": { "uid": "123", "name": "ç”¨æˆ·å" },
      "timestamp": 1234567890000,
      "content": { "text": "æ¶ˆæ¯å†…å®¹" },
      "recalled": false,
      "system": false
    }
  ]
}
```

**è¾“å‡ºæ ¼å¼ï¼š**

```json
{
  "messages": [{ "sender_name": "ç”¨æˆ·å", "text": "åˆå¹¶åçš„æ¶ˆæ¯å†…å®¹" }]
}
```

---

### generate_training_data.py

ä½¿ç”¨ Gemini API å¯¹èŠå¤©æ¶ˆæ¯è¿›è¡Œè‡ªåŠ¨æ ‡æ³¨ï¼Œç”Ÿæˆç”¨äºæ¨¡å‹å¾®è°ƒçš„è®­ç»ƒæ•°æ®ã€‚

**åŠŸèƒ½ï¼š**

- è°ƒç”¨ Gemini 2.5 Flash API è‡ªåŠ¨æ ‡æ³¨æ¶ˆæ¯
- ä¸‰åˆ†ç±»æ ‡ç­¾ï¼šlow_value (0), normal (1), interrupt (2)
- æ”¯æŒéšæœºé‡‡æ ·ã€è¿›åº¦è·Ÿè¸ªã€é”™è¯¯é‡è¯•
- è‡ªåŠ¨éªŒè¯æ•°æ®è´¨é‡

**ç”¨æ³•ï¼š**

```bash
python scripts/generate_training_data.py input.json -o training_data.json
```

**å‚æ•°ï¼š**

| å‚æ•°                | è¯´æ˜                               | é»˜è®¤å€¼                           |
| ------------------- | ---------------------------------- | -------------------------------- |
| `input_file`        | è¾“å…¥èŠå¤©æ¶ˆæ¯ JSON æ–‡ä»¶è·¯å¾„ï¼ˆå¿…éœ€ï¼‰ | -                                |
| `-o, --output`      | è¾“å‡ºè®­ç»ƒæ•°æ®æ–‡ä»¶è·¯å¾„               | `./training_data.json`           |
| `-n, --sample-size` | éšæœºé‡‡æ ·æ¶ˆæ¯æ•°é‡                   | `800`                            |
| `--seed`            | éšæœºç§å­ï¼ˆç”¨äºå¯é‡ç°æ€§ï¼‰           | `None`                           |
| `--api-key`         | Gemini API key                     | ä»ç¯å¢ƒå˜é‡ `GEMINI_API_KEY` è¯»å– |
| `--model`           | Gemini æ¨¡å‹åç§°                    | `gemini-2.5-flash-lite`          |
| `--temperature`     | é‡‡æ ·æ¸©åº¦ï¼ˆ0.0 = æ›´ç¡®å®šæ€§ï¼‰         | `0.0`                            |
| `--retry-attempts`  | API è°ƒç”¨å¤±è´¥æ—¶çš„é‡è¯•æ¬¡æ•°           | `3`                              |
| `--retry-delay`     | é‡è¯•ä¹‹é—´çš„å»¶è¿Ÿï¼ˆç§’ï¼‰               | `1.0`                            |
| `--no-validate`     | è·³è¿‡è¾“å‡ºæ•°æ®éªŒè¯                   | `false`                          |

**è¯„åˆ†æ ‡å‡†ï¼š**

| æ ‡ç­¾            | åˆ†æ•°èŒƒå›´  | ç‰¹å¾                                           | ç¤ºä¾‹                                   |
| --------------- | --------- | ---------------------------------------------- | -------------------------------------- |
| `low_value` (0) | 0.0 - 0.3 | çº¯è¡¨æƒ…ã€ç®€çŸ­ç¬‘å£°ã€æ— å®è´¨å†…å®¹                   | "å“ˆå“ˆå“ˆ", "233", "ğŸ˜‚ğŸ˜‚ğŸ˜‚"              |
| `normal` (1)    | 0.3 - 0.8 | åŒ…å«å®è´¨æ€§å†…å®¹çš„æ—¥å¸¸å¯¹è¯                       | "ä»Šå¤©å¤©æ°”çœŸå¥½å•Š", "æˆ‘è§‰å¾—å¯ä»¥è¿™æ ·è§£å†³" |
| `interrupt` (2) | 0.8 - 1.0 | å°é çŸ¥èŠ±ç›¸å…³å†…å®¹ï¼ˆè½»å°è¯´ã€Šè´¥çŠ¬å¥³ä¸»å¤ªå¤šäº†ï¼ã€‹ï¼‰ | "å°é å¥½å¯çˆ±", "è´¥çŠ¬å¥³ä¸»å¤ªå¤šäº†çœŸå¥½çœ‹"   |

**ç¤ºä¾‹ï¼š**

```bash
# ä½¿ç”¨é»˜è®¤è®¾ç½®
python scripts/generate_training_data.py chat.json

# è‡ªå®šä¹‰é‡‡æ ·æ•°é‡å’Œéšæœºç§å­
python scripts/generate_training_data.py chat.json -n 1000 --seed 42

# æŒ‡å®šè¾“å‡ºæ–‡ä»¶
python scripts/generate_training_data.py chat.json -o data/train.json

# ä½¿ç”¨è‡ªå®šä¹‰ API key
python scripts/generate_training_data.py chat.json --api-key YOUR_API_KEY
```

**è¾“å‡ºæ ¼å¼ï¼š**

```json
[
  {
    "message": "ä»Šå¤©å¤©æ°”çœŸå¥½å•Š",
    "context": "",
    "label": 1
  },
  {
    "message": "å°é å¥½å¯çˆ±",
    "context": "",
    "label": 2
  }
]
```

---

### download_model.py

ä» HuggingFace ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹å’Œåˆ†è¯å™¨ã€‚

**ç”¨æ³•ï¼š**

```bash
python scripts/download_model.py --model-name hfl/chinese-bert-wwm-ext --output-dir ./models
```

**å‚æ•°ï¼š**

| å‚æ•°           | è¯´æ˜                             | é»˜è®¤å€¼                     |
| -------------- | -------------------------------- | -------------------------- |
| `--model-name` | HuggingFace æ¨¡å‹åç§°             | `hfl/chinese-bert-wwm-ext` |
| `--output-dir` | è¾“å‡ºç›®å½•                         | `./models`                 |
| `--token`      | HuggingFace è®¿é—®ä»¤ç‰Œï¼ˆç§æœ‰æ¨¡å‹ï¼‰ | `null`                     |
| `--list`       | åˆ—å‡ºä¸‹è½½çš„æ–‡ä»¶                   | `false`                    |
| `--log-level`  | æ—¥å¿—çº§åˆ«                         | `INFO`                     |

**ç¤ºä¾‹ï¼š**

```bash
# ä¸‹è½½é»˜è®¤æ¨¡å‹
python scripts/download_model.py

# ä¸‹è½½è‡ªå®šä¹‰æ¨¡å‹
python scripts/download_model.py --model-name bert-base-chinese --output-dir ./custom-model

# ä¸‹è½½ç§æœ‰æ¨¡å‹ï¼ˆéœ€è¦ tokenï¼‰
python scripts/download_model.py --model-name org/private-model --token hf_xxx

# ä¸‹è½½ååˆ—å‡ºæ–‡ä»¶
python scripts/download_model.py --list
```

---

### benchmark.py

æ€§èƒ½åŸºå‡†æµ‹è¯•è„šæœ¬ï¼Œç”¨äºæµ‹è¯•æ¨ç†ååé‡å’Œå»¶è¿Ÿã€‚

**ç”¨æ³•ï¼š**

```bash
python scripts/benchmark.py --model-path ./models/model.onnx
```

**å‚æ•°ï¼š**

| å‚æ•°               | è¯´æ˜          | é»˜è®¤å€¼                |
| ------------------ | ------------- | --------------------- |
| `--model-path`     | ONNX æ¨¡å‹è·¯å¾„ | `./models/model.onnx` |
| `--tokenizer-path` | åˆ†è¯å™¨è·¯å¾„    | ä¸æ¨¡å‹ç›¸åŒ            |
| `--batch-size`     | æ‰¹æ¬¡å¤§å°      | `1`                   |
| `--num-requests`   | è¯·æ±‚æ•°é‡      | `100`                 |
| `--num-warmup`     | é¢„çƒ­è¯·æ±‚æ•°    | `10`                  |
| `--max-length`     | æœ€å¤§åºåˆ—é•¿åº¦  | `128`                 |
| `--enable-cache`   | å¯ç”¨ç¼“å­˜æµ‹è¯•  | `true`                |
| `--log-level`      | æ—¥å¿—çº§åˆ«      | `INFO`                |

**ç¤ºä¾‹ï¼š**

```bash
# åŸºç¡€æµ‹è¯•
python scripts/benchmark.py --model-path ./models/model.onnx

# é«˜è´Ÿè½½æµ‹è¯•
python scripts/benchmark.py --model-path ./models/model.onnx --batch-size 16 --num-requests 1000

# æ‰¹é‡æµ‹è¯•
python scripts/benchmark.py --model-path ./models/model.onnx --batch-size 32 --num-requests 500
```

**è¾“å‡ºç¤ºä¾‹ï¼š**

```
==================================================
BENCHMARK RESULTS
==================================================

### Single Request Latency ###
  min: 10.23 ms
  max: 18.45 ms
  mean: 12.50 ms
  median: 12.10 ms
  p50: 12.10 ms
  p90: 14.20 ms
  p95: 14.80 ms
  p99: 16.80 ms
  stdev: 1.85 ms

### Throughput ###
  Total time: 8.03 s
  Total requests: 1000
  Requests/sec: 124.72
  Batch size: 16

### Cache Effectiveness ###
  Unique requests: 50
  Repeat requests: 50
  Speedup: 8.20x
  Potential hit rate: 50.0%

==================================================
```

---

### health_check.py

æœåŠ¡å¥åº·æ£€æŸ¥è„šæœ¬ï¼Œæ”¯æŒæŒç»­ç›‘æ§æ¨¡å¼å’Œ CI/CD é›†æˆã€‚

**ç”¨æ³•ï¼š**

```bash
python scripts/health_check.py --base-url http://localhost:8000
```

**å‚æ•°ï¼š**

| å‚æ•°             | è¯´æ˜                     | é»˜è®¤å€¼                  |
| ---------------- | ------------------------ | ----------------------- |
| `--base-url`     | æœåŠ¡åŸºç¡€ URL             | `http://localhost:8000` |
| `--timeout`      | è¯·æ±‚è¶…æ—¶ï¼ˆç§’ï¼‰           | `5`                     |
| `--interval`     | æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼ŒæŒç»­æ¨¡å¼ï¼‰ | `10`                    |
| `--continuous`   | æŒç»­ç›‘æ§æ¨¡å¼             | `false`                 |
| `--max-failures` | æœ€å¤§å¤±è´¥æ¬¡æ•°ï¼ˆé€€å‡ºï¼‰     | `3`                     |
| `--check-model`  | åŒæ—¶æ£€æŸ¥æ¨¡å‹æ¨ç†ç«¯ç‚¹     | `false`                 |
| `--verbose`      | è¯¦ç»†è¾“å‡º                 | `false`                 |

**ç¤ºä¾‹ï¼š**

```bash
# å•æ¬¡æ£€æŸ¥
python scripts/health_check.py --base-url http://localhost:8000

# æŒç»­ç›‘æ§
python scripts/health_check.py --base-url http://localhost:8000 --continuous --interval 30

# CI/CD é›†æˆï¼ˆå¤±è´¥æ—¶éé›¶é€€å‡ºç ï¼‰
python scripts/health_check.py --base-url http://localhost:8000 --max-failures 1

# åŒ…å«æ¨¡å‹æ¨ç†æ£€æŸ¥
python scripts/health_check.py --base-url http://localhost:8000 --check-model

# è¯¦ç»†æ¨¡å¼
python scripts/health_check.py --base-url http://localhost:8000 --verbose
```

**é€€å‡ºç ï¼š**

| é€€å‡ºç  | è¯´æ˜                 |
| ------ | -------------------- |
| `0`    | å¥åº·æ£€æŸ¥é€šè¿‡         |
| `1`    | å¥åº·æ£€æŸ¥å¤±è´¥         |
| `2`    | é”®ç›˜ä¸­æ–­ï¼ˆç”¨æˆ·ç»ˆæ­¢ï¼‰ |

---

## å·¥ä½œæµç¤ºä¾‹

### å®Œæ•´è®­ç»ƒæ•°æ®å‡†å¤‡æµç¨‹

```bash
# 1. å¤„ç†åŸå§‹èŠå¤©è®°å½•
python scripts/process_chat.py raw_chat.json -o processed_chat.json

# 2. ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼ˆéœ€è¦è®¾ç½® GEMINI_API_KEY ç¯å¢ƒå˜é‡ï¼Œ-n ä¸ºéšæœºé‡‡æ ·æ•°é‡ï¼Œé»˜è®¤ 800ï¼‰
export GEMINI_API_KEY=your_api_key
python scripts/generate_training_data.py processed_chat.json -n 800 -o training_data.json

# 3. è®­ç»ƒæ¨¡å‹
python training/train.py --data-path training_data.json --output-dir ./output

# 4. å¯¼å‡º ONNX æ¨¡å‹
python training/export_onnx.py --model-path ./output/checkpoint-best --output-path ./models/model.onnx

# 5. æ€§èƒ½æµ‹è¯•
python scripts/benchmark.py --model-path ./models/model.onnx

# 6. éƒ¨ç½²åå¥åº·æ£€æŸ¥
python scripts/health_check.py --base-url http://localhost:8000 --check-model
```

---

## å¼€å‘æ–°è„šæœ¬

éµå¾ªä»¥ä¸‹çº¦å®šï¼š

1. **å‚æ•°è§£æ**ï¼šä½¿ç”¨ `argparse` å¹¶æä¾› `--help`
2. **æ—¥å¿—**ï¼šä½¿ç”¨ `logging` æ¨¡å—ï¼Œæ”¯æŒ `--log-level`
3. **é€€å‡ºç **ï¼šä½¿ç”¨é€‚å½“çš„æ ‡å‡†é€€å‡ºç 
4. **æ–‡æ¡£**ï¼šåœ¨æ–‡ä»¶é¡¶éƒ¨æ·»åŠ æ–‡æ¡£å­—ç¬¦ä¸²
5. **ç±»å‹æ³¨è§£**ï¼šä½¿ç”¨ Python 3.13 ç±»å‹åˆ«åè¯­æ³•

**æ¨¡æ¿ï¼š**

```python
#!/usr/bin/env python
"""è„šæœ¬æè¿°

ç”¨æ³•:
    python scripts/script_name.py [options]
"""

import argparse
import logging
import sys
from pathlib import Path

# ç±»å‹åˆ«åï¼ˆPython 3.13ï¼‰
type Config = dict[str, str | int]


def setup_logging(log_level: str = "INFO") -> logging.Logger:
    """è®¾ç½®æ—¥å¿—

    Args:
        log_level: æ—¥å¿—çº§åˆ«

    Returns:
        é…ç½®å¥½çš„ logger
    """
    logging.basicConfig(
        format="%(asctime)s - %(levelname)s - %(message)s",
        level=getattr(logging, log_level.upper()),
        handlers=[logging.StreamHandler(sys.stdout)],
    )
    return logging.getLogger(__name__)


def main() -> None:
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="è„šæœ¬æè¿°",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )

    parser.add_argument(
        "--log-level",
        type=str,
        default="INFO",
        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
        help="Logging level",
    )

    args = parser.parse_args()

    # è®¾ç½®æ—¥å¿—
    logger = setup_logging(args.log_level)

    # è„šæœ¬é€»è¾‘
    logger.info("Running script...")


if __name__ == "__main__":
    main()
```
